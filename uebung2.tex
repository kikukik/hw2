\documentclass[
ngerman,
]{tudaexercise}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{array}
\usepackage{gauss}
\usepackage{graphicx}
\usepackage{lipsum}% For example text
\usepackage{listings}
\graphicspath{ {./images/} }
\newcommand{\sni}{\sum_{i=1}^{n}}

\begin{document}
	
	\title[Uebung]{SML: Exercise 2}
	\author{Rinor Cakaj, Patrick Nowak}
	\term{Summer Term 2020}
	\sheetnumber{1}
	
	\maketitle
	
	\begin{task}{Density Estimation}
		We are given data C1 and C2, which we suppose to be generated by 2D-Gaussians with parameters ${\mu_1,\Sigma_1}$ and ${\mu_2,\Sigma_2}$, respectively.
		\begin{subtask}
			Assume we are given iid. datapoints $x_i, i=1,..,n$ which are generated by a 2D-Gaussian. Following the max-likelihood principle, we maximize the log-likelihood function
			\begin{align*}
				l(\mu,\Sigma,x_1,...,x_n)=\ln(\prod_{i=1}^n p(x_i|\mu,\Sigma))=\sni\ln(p(x_i|\mu,\Sigma))
			\end{align*}
			for the Gaussian probability density
			\begin{align} p(x|\mu,\Sigma)=\frac{1}{\sqrt{(2\pi)^k|\Sigma|}}\exp\left( -\frac{1}{2}(x-\mu)^T\Sigma(x-\mu)\right)\;.
			\end{align}
			We receive
			\begin{align}
			l(\mu,\Sigma):=l(\mu,\Sigma,x_1,...,x_n)&=\sni\left( -\frac{k}{2}\ln(2\pi)-\frac{1}{2}ln(|\Sigma|)-\frac{1}{2}(x_i-\mu)^T\Sigma(x_i-\mu)\right) \\
			&=-\frac{nk}{2}\ln(2\pi)-\frac{n}{2}ln(|\Sigma|)-\frac{1}{2}\sni (x_i-\mu)^T\Sigma(x_i-\mu)\;\;.
			\end{align}
			We compute the derivatives w.r.t. $\mu$ and $\Sigma$ and set them equal to zero. This yields
			\begin{align*}
\frac{d}{d\mu}l(\mu,\Sigma,x_1,...,x_n)&=\frac{d}{d\mu}\; -\frac{1}{2}\sni (x_i-\mu)^T\Sigma (x_i-\mu)\\ &= -\sni \frac{d}{d\mu}\frac{1}{2}(x_i-\mu)^T\Sigma (x_i-\mu)\;\;.
			\end{align*}
			Using the matrix identity $\frac{d}{dw}\frac{w^T Aw}{dw}=2Aw$ which holds if $w$ does not depend on $A$ and if $A$ is symmetric, we get (with $w=(x-\mu), dw=-d\mu$)
			\begin{align*}
			0&\stackrel{!}{=}\frac{d}{d\mu}l(\mu,\Sigma,x_1,...,x_n)\\
			0&\stackrel{!}{=}-\sni \Sigma^{-1}(x_i-\mu)	\;\;.
			\end{align*}
			Finally, we use that $\Sigma^{-1}$ is positive definite, so we can leave it out here and get
			\begin{align*}
				0&\stackrel{!}{=}n\mu-\sni x_i\;\;,
			\end{align*}
			which is solved for the MLE-estimate
			\begin{align}
				\hat{\mu}&=\frac{1}{n}\sni x_i\;\;.
			\end{align}
		\end{subtask}
	\end{task}
	
\end{document}